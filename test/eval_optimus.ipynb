{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heegyukim\\Desktop\\project\\latent-diffusion-lm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "from src.task.optimus_v2 import OptimusTask as OptimusTaskV2\n",
    "from src.task.optimus import OptimusTask as OptimusTaskV1\n",
    "from coop.metric import levenshtein_batch, levenshtein\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt = \"checkpoint/optimus-v2-44M/optimus-v2-tiny-vae.ckpt\"\n",
    "ckpt = \"checkpoint/optimus-v2-44M/optimus-v2-tiny-vae.ckpt\"\n",
    "# ckpt = \"checkpoint/optimus-v1-base-500k.ckpt\"\n",
    "task = OptimusTaskV2.load_from_checkpoint(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1cfadde3880>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요\n",
      "오늘도 즐거운, 하루 ~\n",
      "살다 보면, 이런 날도 있는 것 아니겠니?\n",
      "그러니 가끔은 좀 편하게 쉬어도 된다.\n",
      "살다 보면, 이런 거도 있겠죠. 돈은 아니니 가끔 편하게 쉬는게 좀 된다.\n",
      "우리 아들, 서울대 합격했어!\n",
      "차 마리오 이것이시간왔는데 여태 몰라서 못썼네요\n",
      "얼음맥주 일본이 미개했었다는 수준 잘보고갑니다.\n",
      "장관은 16일 평양판위원회에서 미국외교장관과 만나 북미, 남북대화에 관해 논의할 예정이다.\n",
      "당초 가족들을장하였으며 전직 대통령에 대한 추진하였지만 아기와 국민의 추모기로 국민열장으로 치러졌다.\n",
      "컴퓨터 과학을 이어지면서도 방대한 문제가며, 과학 전체로서 그 경영관리에 있어 혁신의 과학 가치가 있는 사이비체임을 명확히 할 수도 있다.\n",
      "이 상태에서 느낀 토도혈귀를 전염시키지는 않지만, 시쉬라이즈와 스케줄 시량의 피를 모두 소모한다.\n",
      "이 대화에서는 김태규를 받은 것이라고 하는 한 사람은 김계원에게 확고한 의지를 보여주고, 태어날 것을 위해 말해버린 것으로 하였다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'이 대화에서는 김태규를 받은 것이라고 하는 한 사람은 김계원에게 확고한 의지를 보여주고, 태어날 것을 위해 말해버린 것으로 하였다.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reconstruct(text, show=True):\n",
    "    latent = task.encode(text)\n",
    "    rec = task.generate(latent, max_length=64, num_beams=4)[0]\n",
    "    if show:\n",
    "        print(rec)\n",
    "    return rec\n",
    "\n",
    "reconstruct(\"안녕하세요\")\n",
    "reconstruct(\"오늘도, 즐거운 하루~ ㅎㅎ\")\n",
    "reconstruct(\"살다 보면, 이런 날도 있는 것 아니겠니?\")\n",
    "reconstruct(\"그러니 가끔은 좀 편하게 쉬어도 된다.\")\n",
    "reconstruct(\"살다 보면, 이런 날도 있는 것 아니겠니? 그러니 가끔은 좀 편하게 쉬어도 된다.\")\n",
    "reconstruct(\"우리 아들, 서울대 합격했어!\")\n",
    "reconstruct(\"차 산지 1년이나 됐는데 여태 몰라서 못썼네요\")\n",
    "reconstruct(\"얼음맥주 일본이 미개했었다는 수준 잘보고갑니다.\")\n",
    "reconstruct(\"틸러슨 장관은 16일 워싱턴에서 미국외교장관과 만나 북미, 남북대화에 관해 논의할 예정이다.\")\n",
    "reconstruct(\"당초 유족들은 가족장을 추진하였으나 전직 대통령에 대한 예우와 전 국민적인 추모열기로 국민장으로 치러졌다.\")\n",
    "reconstruct(\"컴퓨터 과학을 둘러싼 논의가 활발해졌지만, 그 전체로서 컴퓨터 과학이 경영관리의 혁신에 있어서 진실로 가치 있는 과학체계임을 명백히 할 필요가 있다.\")\n",
    "reconstruct(\"이 상태에서 누굴 물어도 흡혈귀로 전염시키지는 않지만, 메모라이즈 시와 캐스팅 시 모두 일정량의 피를 소모한다.\")\n",
    "reconstruct(\"이 대화에서 김재규가 자신은 한다면 하는 사람이라고 한 것은 김계원에게 확고한 결의를 보여주고 믿음을 주기 위해 했던 말인 것으로 짐작된다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "언제 이 나라는 좀 평온해질까?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'언제 이 나라는 좀 평온해질까?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruct(\"언제쯤 이 나라는 좀 평온해질까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 63.0/63.0 [00:00<00:00, 63.0kB/s]\n",
      "Using custom data configuration heegyu--vae_eval-5adb9ae751b4aeab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/heegyu--vae_eval to C:/Users/heegyukim/.cache/huggingface/datasets/heegyu___parquet/heegyu--vae_eval-5adb9ae751b4aeab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 54.1k/54.1k [00:00<00:00, 312kB/s] \n",
      "Downloading data files: 100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Parameter 'function'=<function reconstruct_batch at 0x000001CFFFBF94C0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to C:/Users/heegyukim/.cache/huggingface/datasets/heegyu___parquet/heegyu--vae_eval-5adb9ae751b4aeab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [05:20<00:45, 45.79s/ba]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': \"그는 ▲인적자본 개발의 기회 불평등 ▲중상류층의 불공정한 기회 가로채기 등을 청년 불평등 원인으로 꼽았다.김 기획총장은 '중상류층의 경우 노동시장에서 큰 가치로 인정되는 능력을 개발할 수 있는 기회가 많다.\",\n",
       " 'reconstruct': \"그는 ▲자본적 수준의 소외등인력 대기업과 복잡한 사례들의 냉대기'이라는 공약과 청년 잡았다. 하지만 금융감독의 인식에서는 시장에서 생활할 수 없는 자가능한 가치의 개발률로 평가되는 등의 생활권을\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reconstruct_batch(x):\n",
    "    r = task.generate(task.encode(x[\"sentence\"]), max_length=64, early_stopping=True)\n",
    "    return {\n",
    "        \"reconstruct\": r\n",
    "    }\n",
    "\n",
    "\n",
    "eval_ds = load_dataset(\"heegyu/vae_eval\", split=\"test\", use_auth_token=True)\n",
    "eval_ds = eval_ds.map(reconstruct_batch, batched=True, batch_size=64)\n",
    "eval_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3688067437110688"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein_batch(eval_ds[\"sentence\"], eval_ds[\"reconstruct\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '민주진보세력 대통합론과 위기.', 'reconstruct': '민주력세서리합론과 위기.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ds[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:  ㅋㅋ 오늘도 앉아서 게임밖에 안함\n",
      "요즘 롤하는거 진짜 존잼임 8.493880271911621\n",
      "요즘 롤하는거 진짜 존잼임, 요즘은 진짜 게임밖에 안함 ㅋㅋㅋ. 하 맨날 이러고 살았으면 좋겠다 진짜 8.52364444732666\n",
      "엄마 오늘 저녁은 고기 먹고싶다. 7.8122406005859375\n",
      "할 일도 없고 너무 심심한듯 9.135533332824707\n",
      "source:  ㅋㅋ 오늘도 앉아서 게임밖에 안함\n",
      "요즘 롤하는거 진짜 존잼임 22.217327117919922\n",
      "요즘 롤하는거 진짜 존잼임, 요즘은 진짜 게임밖에 안함 ㅋㅋㅋ. 하 맨날 이러고 살았으면 좋겠다 진짜 14.96523666381836\n",
      "엄마 오늘 저녁은 고기 먹고싶다. 26.74239158630371\n",
      "할 일도 없고 너무 심심한듯 17.033100128173828\n"
     ]
    }
   ],
   "source": [
    "# 유사한 문장 길이, 겹치는 단어가 많아야 하는 듯\n",
    "\n",
    "def cosine_simm(text, targets):\n",
    "    src = task.encode(text)  # (1, 512)\n",
    "    tgt = task.encode(targets) # (n, 512)\n",
    "    scores = torch.matmul(src, tgt.T)[0]\n",
    "    print(\"source: \", text)\n",
    "    for t, s in zip(targets, scores.tolist()):\n",
    "        print(t, s)\n",
    "\n",
    "def euclid_simm(text, targets):\n",
    "    src = task.encode(text)  # (1, 512)\n",
    "    tgt = task.encode(targets) # (n, 512)\n",
    "    src = src.repeat((tgt.shape[0], 1))\n",
    "    dist = torch.sqrt(((tgt - src) ** 2).sum(-1))\n",
    "\n",
    "    print(\"source: \", text)\n",
    "    for t, s in zip(targets, dist.tolist()):\n",
    "        print(t, s)\n",
    "\n",
    "text = \"ㅋㅋ 오늘도 앉아서 게임밖에 안함\"\n",
    "targets = [\n",
    "    \"요즘 롤하는거 진짜 존잼임\",\n",
    "    \"요즘 롤하는거 진짜 존잼임, 요즘은 진짜 게임밖에 안함 ㅋㅋㅋ. 하 맨날 이러고 살았으면 좋겠다 진짜\",\n",
    "    \"엄마 오늘 저녁은 고기 먹고싶다.\",\n",
    "    \"할 일도 없고 너무 심심한듯\"\n",
    "]\n",
    "euclid_simm(text, targets)\n",
    "cosine_simm(text, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arithmetic 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\transformers\\generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우리 아들, 서울대 합격했어! - 서울대 + 고려대 = 우리 아들 고려대 합격했어!\n",
      "우리 아들, 서울대 합격했어! - 아들 + 딸 = 우리 딸, 서울대 합격했어!\n",
      "오빠, 요즘 회사생활은 어때? - 회사 + 학교 = 오빠, 학교 요즘생활은 어때?\n",
      "오빠, 요즘 회사생활은 어때? - 오빠 회사 + 언니 학교 = 언니, 요즘 학교생활은 어때?\n",
      "나 요즘 고양이 키우는데 너무 귀엽더라 ㅎㅎ - 고양이 + 강아지 = 나 자전거 강아지 키우는데 너무 귀엽더라\n",
      "나 요즘 고양이 키우는데 너무 귀엽더라 ㅎㅎ - 귀엽다 + 사랑스럽다 = 나 요즘 사회 키우는데 너무 사랑스럽더라\n"
     ]
    }
   ],
   "source": [
    "def arithmetic(src, sub, add):\n",
    "    x = task.encode([src, sub, add])\n",
    "    z = x[0] - x[1] + x[2]\n",
    "    print(src, \"-\", sub, \"+\", add, \"=\", task.generate(z.unsqueeze(0))[0])\n",
    "\n",
    "arithmetic(\n",
    "    \"우리 아들, 서울대 합격했어!\",\n",
    "    \"서울대\",\n",
    "    \"고려대\"\n",
    ")\n",
    "\n",
    "arithmetic(\n",
    "    \"우리 아들, 서울대 합격했어!\",\n",
    "    \"아들\",\n",
    "    \"딸\"\n",
    ")\n",
    "\n",
    "arithmetic(\n",
    "    \"오빠, 요즘 회사생활은 어때?\",\n",
    "    \"회사\",\n",
    "    \"학교\"\n",
    ")\n",
    "\n",
    "arithmetic(\n",
    "    \"오빠, 요즘 회사생활은 어때?\",\n",
    "    \"오빠 회사\",\n",
    "    \"언니 학교\"\n",
    ")\n",
    "\n",
    "arithmetic(\n",
    "    \"나 요즘 고양이 키우는데 너무 귀엽더라 ㅎㅎ\",\n",
    "    \"고양이\",\n",
    "    \"강아지\"\n",
    ")\n",
    "\n",
    "arithmetic(\n",
    "    \"나 요즘 고양이 키우는데 너무 귀엽더라 ㅎㅎ\",\n",
    "    \"귀엽다\",\n",
    "    \"사랑스럽다\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3130)\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:240: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "d:\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:203: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "def latent_diff(a, b):\n",
    "    x = task.encode([a, b])\n",
    "    z = x[0] - x[1]\n",
    "    print(z.abs().mean())\n",
    "\n",
    "    print(pd.Series(z.numpy()).plot.hist())\n",
    "\n",
    "latent_diff(\n",
    "    \"우리 아들, 서울대 합격했어!\",\n",
    "    \"나 요즘 고양이 키우는데 너무 귀엽더라 ㅎㅎ\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 친구와 도시락을 누르고 외모다.\n",
      "이 꽁이아요 그리고 소련페이지같혀 어\n",
      "이렇게보 절벽에 오긴만고 그 함성로 보이는 것.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def summarize(texts):\n",
    "    texts = texts.strip().split(\"\\n\")\n",
    "    x = task.encode(texts).mean(0)\n",
    "    print(task.generate(x.unsqueeze(0), max_length=64, num_beams=4)[0])\n",
    "\n",
    "summarize(\"\"\"\n",
    "나는 오늘 친구와 만났다. \n",
    "나는 친구와 피자를 먹고 맥주를 마셨다. \n",
    "나와 친구는 밥을 먹고 보드게임 카페를 갔다. \n",
    "거기서 할리갈리를 했는데 매우 재미 있었다.\n",
    "\"\"\")\n",
    "\n",
    "summarize(\"\"\"\n",
    "이 겜 진짜 핵노잼인데\n",
    "이럴거면 게임 왜 만듦?? ㅋㅋㅋ ㅈㄴ 노어이\n",
    "노잼이네요, 회사 문 닫으셈 ㅅㄱㅋ\n",
    "\"\"\")\n",
    "\n",
    "summarize(\"\"\"\n",
    "잠시 마음을 놓는 순간 거세지는 게 이곳의 바람. \n",
    "마을을 떠나는 길에는 구름까지 잔뜩 몰려오더니 결국 비바람이 몰아치기 시작했다. \n",
    "하필 오늘은 펭귄 서식지에 오기로 한 날.\n",
    "풀들이 다 휘어버릴 만큼 거센 바람을 보니 여기 사는 펭귄들이 걱정됐다. \n",
    "여기에서 돌아갈 수도 없다. \n",
    "이런 날씨에 펭귄이 있을까 걱정했는데 입구부터 귀여운 울음소리가 들닌다. \n",
    "손님을 처음으로 반겨준 이 녀석. \n",
    "장난감 나팔 같은 목소리가 독특하다.\n",
    "얼음이 아닌 따뜻한 땅을 좋아하는 마젤란 펭귄은 이곳에 집을 짓고 매년 봄, 여름을 보낸다. \n",
    "신기하게도 같은 집에서 같은 암수가 매년 만나 이렇게 예쁜 새끼를 낳고 여름 내내 수영을 가르쳐서 가을이 되면 더 따뜻한 브라질로 떠난다고 한다. \n",
    "바람부는 허허벌판에서 5kg의 몸으로 버티는 펭귄들이 기특해 보였다. \n",
    "한 녀석은 길목에서 손님을 기다리고 있는 것 같더니 따라나서자 이렇게 줄행랑을 친다.\n",
    "따라 잡을 수 없을 만큼 빨랐다. \n",
    "다가서자 신기한 듯 이리저리 고개를 돌리며 구경이다.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paraphrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잠시 마음을 놓는 순간 거세지는 게 이곳의 바람.  -> 교통비 마음을 놓는 지난 정도는 거는 삶이 소형 같아.\n",
      "마을을 떠나는 길에는 구름까지 잔뜩 몰려오더니 결국 비바람이 몰아치기 시작했다.  -> 마을로 떠나서 길에는 발을 건드리지 하고 난 억패패분도 생각하고 부럽다\n",
      "하필 오늘은 펭귄 서식지에 오기로 한 날. -> 하필 *은 KT에 오기로 한 날이다\n",
      "풀들이 다 휘어버릴 만큼 거센 바람을 보니 여기 사는 펭귄들이 걱정됐다.  -> 풀들이랑 싸어버릴수록 빗도 부는데 사는거든...\n",
      "여기에서 돌아갈 수도 없다.  -> 여기에서 올라갈 수도 없다.\n",
      "나는 오늘 친구와 만났다.  -> 나는 오늘 친구와 만났다.\n",
      "나는 친구와 피자를 먹고 맥주를 마셨다.  -> 나는 엄마우 디저트를 먹고 맥주 사왔다.\n",
      "나와 친구는 밥을 먹고 보드게임 카페를 갔다.  -> 울 친구는 밥을 먹고 보드게임 티비장왔다.\n",
      "거기서 할리갈리를 했는데 매우 재미 있었다. -> 거기서 언제갈때 사는데 잘 다를 게 없었네\n",
      "나 요즘 고양이 키우는데 너무 귀엽더라 ㅎㅎ -> 나 요즘 고양이 키우는데 너무 귀엽더라\n",
      "이 겜 진짜 핵노잼인데 -> 이 진짜 넘노잼인데\n",
      "이럴거면 게임 왜 만듦?? ㅋㅋㅋ ㅈㄴ 노어이 -> 뭔지지 말스 왜??ㄴㄴㄴ 노김\n",
      "노잼이네요, 회사 문 닫으셈 ㅅㄱㅋ -> 노잼이 높아, 전세 틀으면 굴러으러ㅎㄱ\n"
     ]
    }
   ],
   "source": [
    "texts = \"\"\"\n",
    "잠시 마음을 놓는 순간 거세지는 게 이곳의 바람. \n",
    "마을을 떠나는 길에는 구름까지 잔뜩 몰려오더니 결국 비바람이 몰아치기 시작했다. \n",
    "하필 오늘은 펭귄 서식지에 오기로 한 날.\n",
    "풀들이 다 휘어버릴 만큼 거센 바람을 보니 여기 사는 펭귄들이 걱정됐다. \n",
    "여기에서 돌아갈 수도 없다. \n",
    "나는 오늘 친구와 만났다. \n",
    "나는 친구와 피자를 먹고 맥주를 마셨다. \n",
    "나와 친구는 밥을 먹고 보드게임 카페를 갔다. \n",
    "거기서 할리갈리를 했는데 매우 재미 있었다.\n",
    "나 요즘 고양이 키우는데 너무 귀엽더라 ㅎㅎ\n",
    "이 겜 진짜 핵노잼인데\n",
    "이럴거면 게임 왜 만듦?? ㅋㅋㅋ ㅈㄴ 노어이\n",
    "노잼이네요, 회사 문 닫으셈 ㅅㄱㅋ\n",
    "\"\"\".strip().split(\"\\n\")\n",
    "import numpy as np\n",
    "\n",
    "def getRandomSamplesOnNSphere(N, R, numberOfSamples):\n",
    "    # Return 'numberOfSamples' samples of vectors of dimension N \n",
    "    # with an uniform distribution on the (N-1)-Sphere surface of radius R.\n",
    "    # RATIONALE: https://mathworld.wolfram.com/HyperspherePointPicking.html\n",
    "    \n",
    "    X = np.random.default_rng().normal(size=(numberOfSamples , N))\n",
    "    return R / np.sqrt(np.sum(X**2, 1, keepdims=True)) * X\n",
    "\n",
    "def paraphrase(text, r=5):\n",
    "    x = task.encode(text)\n",
    "    e = torch.tensor(getRandomSamplesOnNSphere(512, r, 1), dtype=torch.float)\n",
    "    # e = torch.rand_like(x) * 0.5\n",
    "    print(text, \"->\", task.generate(x + e, max_length=64, early_stopping=True)[0])\n",
    "\n",
    "for text in texts:\n",
    "    paraphrase(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
