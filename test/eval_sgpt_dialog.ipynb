{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/latent-diffusion-lm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.task.optimus_v2 import OptimusTask\n",
    "from src.task.sgpt import SGPTTask\n",
    "from coop.metric import levenshtein_batch, levenshtein\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgpt = SGPTTask.load_from_checkpoint(\"outputs/2022-10-18/06-46-26/checkpoint/sgpt-tiny-opt44M.ckpt\") # first\n",
    "# sgpt = SGPTTask.load_from_checkpoint(\"outputs/2022-10-20/00-22-07/checkpoint/sgpt-base-opt44M.ckpt\") # mse 학습\n",
    "sgpt = SGPTTask.load_from_checkpoint(\"outputs/2022-10-20/03-20-29/checkpoint/sgpt-base-opt56M.ckpt\").eval().cuda() # kl-div로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f1154291a60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "자주 가는 맛집 있으세요?\n",
    "동네에 돌곱창집 진짜 자주갓는데ㅜ\n",
    "영업시간제한있고는 못갔어요ㅠ\n",
    "아 곱창 맛있는데요!!\n",
    "양념곱창볶음인데ㅜㅜ 진짜 넘 맛있어요 ㅎㅎㅎ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저기의 선물도 아니엿해도 항상 2 0.07205158472061157\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def get_next_sentence(context, answer):\n",
    "    latents = sgpt.autoencoder.encode(context.strip().split(\"\\n\"))\n",
    "    answer_latent = sgpt.autoencoder.encode(answer)\n",
    "    response_latent = sgpt.model(inputs_embeds=latents, attention_mask=None).latent.loc[-1, :].unsqueeze(0)\n",
    "    # print(response.shape)\n",
    "    response = sgpt.autoencoder.generate(response_latent, max_length=64, num_beams=4, min_length=10)[0]\n",
    "    # mse = ((response_latent - answer_latent) ** 2).sum(-1)\n",
    "    mse = F.mse_loss(response_latent, answer_latent)\n",
    "    print(response, mse.item())\n",
    "    \n",
    "\n",
    "get_next_sentence(\"\"\"\n",
    "자주 가는 맛집 있으세요?\n",
    "동네에 돌곱창집 진짜 자주갓는데ㅜ\n",
    "\"\"\",\n",
    "\"동네에 돌곱창집 진짜 자주갓는데ㅜ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([1, 512]), scale: torch.Size([1, 512]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sgpt.autoencoder.generate(sgpt.autoencoder.encode(\"저 여럿안하는 모아가 없네\"))\n",
    "# sgpt.autoencoder.generate(sgpt.autoencoder.encode(\"동네에 돌곱창집 진짜 자주갓는데ㅜ\"))\n",
    "\n",
    "# F.kl_div(\n",
    "#     torch.FloatTensor([[1, 2, 3, 0]]),\n",
    "#     torch.FloatTensor([[1, 2, 3, 0]]),\n",
    "#     reduction='none',\n",
    "#     log_target=True\n",
    "# )\n",
    "sgpt.autoencoder.encode(\"동네에 돌곱창집 진짜 자주갓는데ㅜ\", return_distribution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7133, 0.1094, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a1 = torch.FloatTensor([[1.4, 0.5, 0.1]])\n",
    "a2 = torch.FloatTensor([[2.0, 0.6, 0.1]])\n",
    "c1 = torch.nn.KLDivLoss(reduction='none')(a1.log(),a2)\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8934), tensor(1.0513))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "\n",
    "def kldiv_loss(p: Normal, attention_mask: Optional[torch.Tensor] = None):\n",
    "    zkl_real = kl_divergence(p, Normal(0, 1))\n",
    "\n",
    "    if attention_mask is not None:\n",
    "        attn_sum = attention_mask.sum()\n",
    "        zkl_real = zkl_real.masked_fill(attention_mask == 0, 0.0)\n",
    "    else:\n",
    "        attn_sum = p.loc.shape[0] * p.loc.shape[1]\n",
    "\n",
    "    kl_mask = torch.gt(zkl_real, 0.5)\n",
    "    zkl = zkl_real[kl_mask].sum() / attn_sum\n",
    "    zkl_real = zkl_real.sum() / attn_sum\n",
    "\n",
    "    return zkl, zkl_real\n",
    "\n",
    "kldiv_loss(\n",
    "    Normal(a1, a2),\n",
    "    torch.LongTensor([[1, 1, 0]])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4000, 0.5000, 0.1000],\n",
       "        [2.0000, 0.6000, 0.1000]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = Normal(a1.squeeze(0), a2.squeeze(0))\n",
    "n2 = Normal(a2.squeeze(0), a1.squeeze(0))\n",
    "n1, n2\n",
    "\n",
    "def stack_normals(normals):\n",
    "    locs = [x.loc for x in normals]\n",
    "    scales = [x.scale for x in normals]\n",
    "    return Normal(\n",
    "        torch.stack(locs),\n",
    "        torch.stack(scales),\n",
    "    )\n",
    "\n",
    "stack_normals([n1, n2]).loc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
