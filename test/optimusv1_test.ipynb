{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heegyukim\\Desktop\\project\\latent-diffusion-lm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.optimus import OptimusPLMDataset, OptimusCollator\n",
    "from src.task.optimus import OptimusTask\n",
    "from transformers import AutoTokenizer\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': {'cls': 'adam', 'learning_rate': 1e-05}, 'logger': {'name': 'wandb'}, 'dataset': {'train': ['heegyu/kowiki-sentences', 'heegyu/namuwiki-sentences', 'heegyu/aihub_web_2021', 'heegyu/aihub_spoken_2021', 'heegyu/aihub_daily_conv_2022_sentences'], 'train_weights': [10, 10, 10, 10, 4], 'test': ['heegyu/vae_eval']}, 'model': {'model': 'optimus', 'encoder': 'klue/bert-base', 'decoder': 'skt/kogpt2-base-v2', 'latent_dim': 768, 'max_seq_len': 64, 'free_bit': 2.0, 'use_plm': True, 'is_vae': True, 'decoder_special_token_id': 51200}, 'trainer': {'optimus_checkout_step': 25000, 'train_batch_size': 32, 'train_steps': 1000000, 'shuffle': False, 'eval_batch_size': 32, 'eval_strategy': 'steps', 'val_check_interval': 50000, 'num_sanity_val_steps': 1, 'project': 'optimus', 'run_name': 'v1-base', 'accelerator': 'gpu'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GlobalHydra.instance().clear()\n",
    "initialize(\"../config/\")\n",
    "config = compose(\"optimus.yaml\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of OptimusDecoder were not initialized from the model checkpoint at skt/kogpt2-base-v2 and are newly initialized: ['transformer.linear_mem.weight', 'transformer.linear_emb.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# task = OptimusTask.load_from_checkpoint(\"checkpoint/optimus-v1-base-50k.ckpt\")\n",
    "task = OptimusTask(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "# task.generate(task.encode(\"안녕하세요\"))\n",
    "# task.generate(task.encode(\"안녕하세요\"))\n",
    "\n",
    "pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1\n",
    ").validate(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = task.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src_input_ids': tensor([[   2,  636, 2259,  ..., 4118, 2116,    3],\n",
      "        [   2, 8061, 2116,  ...,    0,    0,    0],\n",
      "        [   2, 1331, 3661,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2, 1091, 3698,  ...,    0,    0,    0],\n",
      "        [   2, 5691, 8046,  ...,    0,    0,    0],\n",
      "        [   2, 5477, 3698,  ...,    0,    0,    0]]), 'src_attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'src_token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'tgt_input_ids': tensor([[51200,  9258, 20038,  ..., 51200, 51200, 51200],\n",
      "        [51200,  9233, 15803,  ..., 51200, 51200, 51200],\n",
      "        [51200,  9327,  9613,  ..., 51200, 51200, 51200],\n",
      "        ...,\n",
      "        [51200,  9089, 20684,  ..., 51200, 51200, 51200],\n",
      "        [51200, 20226,  9163,  ..., 51200, 51200, 51200],\n",
      "        [51200, 30764,  8688,  ..., 51200, 51200, 51200]]), 'tgt_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'tgt_labels': tensor([[51200,  9258, 20038,  ...,  -100,  -100,  -100],\n",
      "        [51200,  9233, 15803,  ...,  -100,  -100,  -100],\n",
      "        [51200,  9327,  9613,  ...,  -100,  -100,  -100],\n",
      "        ...,\n",
      "        [51200,  9089, 20684,  ...,  -100,  -100,  -100],\n",
      "        [51200, 20226,  9163,  ...,  -100,  -100,  -100],\n",
      "        [51200, 30764,  8688,  ...,  -100,  -100,  -100]])}\n"
     ]
    }
   ],
   "source": [
    "for batch in val_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([51200,  9258, 20038, 24249, 12432, 49549, 22103, 42936, 20038,  8243,\n",
       "         7767,  7461, 11461, 48127,  9715, 22103, 11007,  8346,  6958,  9276,\n",
       "        13445, 42936, 26091, 12637, 32574,  6963, 13153,  8387, 10201,  9194,\n",
       "         8243,  7767,  7461, 11461,  9249,  9725, 29430,  9458, 10727,  7426,\n",
       "        27810, 12635,  9807,  8705,  9025,  9080, 25012,  9146,  9016, 51200,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"tgt_labels\"][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
