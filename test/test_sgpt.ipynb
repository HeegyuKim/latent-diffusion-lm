{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heegyukim\\Desktop\\project\\latent-diffusion-lm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "from src.task.sgpt import SGPTTask\n",
    "from coop.models.sgpt import SentenceGPT\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': {'cls': 'adam', 'learning_rate': 0.0001}, 'logger': {'name': 'wandb'}, 'dataset': {'train': ['heegyu/aihub_daily_conv_2022'], 'test': ['heegyu/aihub_daily_conv_2022']}, 'model': {'model': 'sgpt-tiny.json', 'autoencoder': 'checkpoint/optimus-v2-44M/optimus-v2-tiny-vae.ckpt', 'latent_dim': 512, 'free_bit': 0.5, 'max_seq_len': 16, 'is_vae': False}, 'trainer': {'train_batch_size': 8, 'train_epochs': 20, 'shuffle': False, 'eval_batch_size': 8, 'eval_strategy': 'epoch', 'gradient_clip_val': 1.0, 'weight_clipping': 0.1, 'project': 'sgpt', 'run_name': 'tiny-opt44M', 'num_sanity_val_steps': 0, 'limit_train_batches': 10, 'limit_val_batches': 1}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if GlobalHydra.instance().is_initialized():\n",
    "    GlobalHydra.instance().clear()\n",
    "initialize(\"../config/\")\n",
    "config = compose(\"sgpt\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgpt = SGPTTask(config).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration heegyu--aihub_daily_conv_2022-f0169ea55f3eccaa\n",
      "Reusing dataset parquet (C:\\Users\\heegyukim\\.cache\\huggingface\\datasets\\parquet\\heegyu--aihub_daily_conv_2022-f0169ea55f3eccaa\\0.0.0\\0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 140329,\n",
       " 'depth': 18,\n",
       " 'speakers': [0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
       " 'utterances': ['**는 게임 좋아하니?',\n",
       "  '게임 어떤거 좋아해?',\n",
       "  '게임 잘 못해서,',\n",
       "  '우린 완전 게임 좋아해',\n",
       "  '나는 별로 안 좋아해',\n",
       "  '어떤 게임 주로 하세요?',\n",
       "  '그럼... 보드 게임은 어대',\n",
       "  '게임은 너무 시간낭비야',\n",
       "  '보드게임은 단합하기 좋죵',\n",
       "  '우리는 음 맞고도 치고 루미 큐브도 하고',\n",
       "  '게임 할 시간에 난 책을 읽어',\n",
       "  '요즘 보드게임 카페 잘 되어 있잖아용',\n",
       "  '너 책 2년 동안 한권도 안 읽었...',\n",
       "  '책을 읽는 게 좋아',\n",
       "  '와우 엄청난 지식인',\n",
       "  '보드 게임 카페가 있어?',\n",
       "  '책은 정말 너무신기해',\n",
       "  '넵 요즘 애들 다 보드게임 카페가용 키키'],\n",
       " 'eous': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(sgpt.train_dataloader()))\n",
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, output = sgpt.step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42.9597, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': Normal(loc: torch.Size([16, 512]), scale: torch.Size([16, 512])),\n",
       " 'attention_mask': tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " 'labels': Normal(loc: torch.Size([16, 512]), scale: torch.Size([16, 512]))}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item, sents = sgpt._item_for_train(batch[0][\"utterances\"][:4])\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = item[\"inputs\"], item[\"labels\"]\n",
    "# x.loc - y.loc\n",
    "sgpt.model.kldiv_loss(x, y, attention_mask=item[\"attention_mask\"], use_free_bit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m hidden \u001b[38;5;241m=\u001b[39m sgpt\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m----> 2\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mrsample()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m      3\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m )\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m      5\u001b[0m x \u001b[38;5;241m=\u001b[39m sgpt\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mreparameterize(hidden)\n\u001b[1;32m      6\u001b[0m hidden\u001b[38;5;241m.\u001b[39mshape, x\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "hidden = sgpt.model.model(\n",
    "    inputs_embeds = item[\"inputs\"].rsample().unsqueeze(0),\n",
    "    attention_mask = item[\"attention_mask\"].unsqueeze(0)\n",
    ").last_hidden_state\n",
    "x = sgpt.model.reparameterize(hidden)\n",
    "hidden.shape, x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
