{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/latent-diffusion-lm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.task.sgpt import SGPTTask\n",
    "from coop.models.sgpt import SentenceGPT\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1045933/1463963186.py:3: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(\"../config/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'optimizer': {'cls': 'adam', 'learning_rate': 0.001}, 'logger': {'name': 'wandb'}, 'dataset': {'train': ['heegyu/aihub_daily_conv_2022'], 'test': ['heegyu/aihub_daily_conv_2022']}, 'model': {'model': 'sgpt-mini.json', 'autoencoder': 'checkpoint/optimus-v2-44M/optimus-v2-tiny-vae.ckpt', 'latent_dim': 512, 'free_bit': 0.5, 'max_seq_len': 16, 'is_vae': False}, 'trainer': {'train_batch_size': 256, 'train_epochs': 3, 'shuffle': False, 'eval_batch_size': 256, 'eval_strategy': 'epoch', 'project': 'sgpt', 'run_name': 'base-opt56M', 'num_sanity_val_steps': 1}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if GlobalHydra.instance().is_initialized():\n",
    "    GlobalHydra.instance().clear()\n",
    "initialize(\"../config/\")\n",
    "config = compose(\"sgpt\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgpt = SGPTTask(config).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration heegyu--aihub_daily_conv_2022-ee6ad77711466ab5\n",
      "Reusing dataset parquet (/home/ubuntu/.cache/huggingface/datasets/heegyu___parquet/heegyu--aihub_daily_conv_2022-ee6ad77711466ab5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Using custom data configuration heegyu--aihub_daily_conv_2022-ee6ad77711466ab5\n",
      "Reusing dataset parquet (/home/ubuntu/.cache/huggingface/datasets/heegyu___parquet/heegyu--aihub_daily_conv_2022-ee6ad77711466ab5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 140329,\n",
       " 'depth': 18,\n",
       " 'speakers': [0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
       " 'utterances': ['**는 게임 좋아하니?',\n",
       "  '게임 어떤거 좋아해?',\n",
       "  '게임 잘 못해서,',\n",
       "  '우린 완전 게임 좋아해',\n",
       "  '나는 별로 안 좋아해',\n",
       "  '어떤 게임 주로 하세요?',\n",
       "  '그럼... 보드 게임은 어대',\n",
       "  '게임은 너무 시간낭비야',\n",
       "  '보드게임은 단합하기 좋죵',\n",
       "  '우리는 음 맞고도 치고 루미 큐브도 하고',\n",
       "  '게임 할 시간에 난 책을 읽어',\n",
       "  '요즘 보드게임 카페 잘 되어 있잖아용',\n",
       "  '너 책 2년 동안 한권도 안 읽었...',\n",
       "  '책을 읽는 게 좋아',\n",
       "  '와우 엄청난 지식인',\n",
       "  '보드 게임 카페가 있어?',\n",
       "  '책은 정말 너무신기해',\n",
       "  '넵 요즘 애들 다 보드게임 카페가용 키키'],\n",
       " 'eous': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(sgpt.train_dataloader()))\n",
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, output = sgpt.step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(62.3671, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': Normal(loc: torch.Size([16, 512]), scale: torch.Size([16, 512])),\n",
       " 'attention_mask': tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " 'labels': Normal(loc: torch.Size([16, 512]), scale: torch.Size([16, 512]))}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = sgpt._item_for_train(batch[0][\"utterances\"][:4])\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([16, 512]), scale: torch.Size([16, 512]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# item[\"inputs\"].loc[1] - item[\"labels\"].loc[0]\n",
    "item[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 16, 512]),\n",
       " Normal(loc: torch.Size([1, 16, 512]), scale: torch.Size([1, 16, 512])))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = sgpt.model.model(\n",
    "    inputs_embeds = item[\"inputs\"].rsample().unsqueeze(0),\n",
    "    attention_mask = item[\"attention_mask\"].unsqueeze(0)\n",
    ").last_hidden_state\n",
    "x = sgpt.model.reparameterize(hidden)\n",
    "hidden.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([1, 16, 512]), scale: torch.Size([1, 16, 512]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.distributions import Normal, kl_divergence\n",
    "\n",
    "labels = Normal(\n",
    "    item[\"labels\"].loc.unsqueeze(0),\n",
    "    item[\"labels\"].scale.unsqueeze(0)\n",
    ")\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0166e-01,  2.6448e-01,  4.6458e-01,  1.0069e-01, -1.2405e-01,\n",
      "        -5.1134e-02, -1.4447e-01,  1.1437e-01,  5.2955e-01, -1.9023e-02,\n",
      "         2.8022e-01,  3.5747e-01,  1.6090e-01, -4.1626e-02,  7.3284e-02,\n",
      "        -1.9380e-01,  1.1013e+00,  9.2238e-02,  8.4387e-01,  1.7632e-01,\n",
      "        -2.2174e-01, -4.0417e-01,  7.6656e-02,  3.6906e-01,  9.0171e-02,\n",
      "        -1.3099e-01,  1.6960e-01, -5.4958e-01,  3.4345e-01,  1.7964e-01,\n",
      "         5.0326e-01,  4.7890e-01, -2.0597e-02,  1.7637e-01, -2.6835e-01,\n",
      "         1.7770e-01, -7.9549e-01, -1.0125e-01, -1.0733e-02,  9.0773e-02,\n",
      "         1.6803e-01,  6.4719e-01,  3.9788e-01,  7.4002e-01,  6.0794e-01,\n",
      "         3.9314e-01,  4.8075e-01, -4.4489e-01, -4.4656e-01,  5.4711e-01,\n",
      "        -3.4176e-01, -7.0742e-02, -3.0671e-01, -2.6214e-01,  1.4209e-01,\n",
      "        -2.7931e-01,  3.9125e-01, -4.0892e-01, -7.2583e-01, -3.9219e-01,\n",
      "         3.6348e-02,  1.3070e-01,  2.7684e-01,  3.2558e-01, -2.7234e-01,\n",
      "        -1.1607e-01,  2.2687e-04, -2.6895e-01, -3.6244e-01, -6.1764e-02,\n",
      "         3.7537e-02, -1.1661e-01,  6.1560e-01,  5.2251e-01,  3.6071e-01,\n",
      "        -4.1198e-02,  3.0754e-01, -1.4164e-01,  4.1526e-01, -1.8348e-01,\n",
      "        -7.3576e-01, -1.4624e-01, -2.7801e-01, -1.5189e-01,  4.6064e-01,\n",
      "         3.4223e-01,  1.6201e-01, -4.5055e-01,  5.2783e-01,  2.1306e-01,\n",
      "         3.9551e-01,  1.6018e-01,  8.3903e-02,  3.9555e-01,  4.0223e-01,\n",
      "         8.1741e-02,  7.2691e-02, -1.8705e-01, -3.4472e-01,  1.5177e-02,\n",
      "        -4.4923e-01, -2.7110e-01, -6.0692e-01,  5.3354e-02,  1.5940e-01,\n",
      "         4.7395e-01, -7.4437e-02, -5.4081e-01, -1.0383e-01, -1.9053e-01,\n",
      "        -3.3134e-01, -2.2933e-01,  5.3571e-01,  7.3554e-01, -4.9490e-01,\n",
      "        -4.6313e-02,  7.2159e-01, -3.0795e-01,  1.2015e-01,  4.6069e-02,\n",
      "        -5.4716e-01,  2.9642e-01, -2.8675e-01,  1.6236e-02, -2.6475e-01,\n",
      "        -5.0221e-02, -2.7789e-01,  3.6693e-01,  1.3412e-01,  4.2059e-03,\n",
      "         9.0965e-02, -2.6017e-01, -6.0571e-02,  7.3716e-02,  2.3248e-02,\n",
      "         7.5395e-02,  3.7207e-01,  3.5106e-01, -6.1289e-01, -1.3330e-01,\n",
      "         8.2622e-02,  2.9637e-01,  1.5038e-01,  3.8068e-02,  2.1629e-01,\n",
      "        -2.7436e-01, -2.5386e-01, -3.5808e-01, -1.1197e+00,  1.5006e-01,\n",
      "         2.3750e-01,  3.8912e-01, -6.8386e-02, -6.5915e-01, -2.8284e-02,\n",
      "        -8.2691e-01,  4.0371e-02, -5.6913e-01, -2.2354e-01,  5.2303e-01,\n",
      "        -3.3442e-02, -1.7967e-01, -2.7593e-01,  3.5302e-01,  5.8330e-01,\n",
      "        -2.0036e-01, -2.8930e-01,  5.9976e-02, -2.3129e-01,  5.3076e-01,\n",
      "        -2.3161e-01,  2.2861e-01,  3.2168e-01, -4.3608e-01,  3.6056e-02,\n",
      "         4.2103e-01, -2.9874e-01,  3.6076e-01,  8.1117e-02, -1.2975e-01,\n",
      "        -2.8699e-01, -1.1492e-01, -6.5138e-01, -3.3404e-01,  2.2990e-01,\n",
      "        -5.3618e-01, -2.1210e-01, -3.3088e-01,  1.7906e-02,  5.4934e-01,\n",
      "         2.2054e-01, -6.0841e-01, -6.9526e-03,  3.3248e-01,  6.8723e-03,\n",
      "         2.2241e-01, -2.9783e-01, -7.5067e-01,  4.5526e-01, -1.9323e-01,\n",
      "        -5.8464e-02,  2.8513e-01, -2.5609e-01, -7.4622e-02, -3.7621e-01,\n",
      "        -2.7514e-01,  7.8913e-02,  1.8499e-01,  2.7617e-01, -1.6885e-01,\n",
      "         1.7125e-01, -2.9954e-01, -5.7721e-01,  6.0173e-02, -1.4453e-01,\n",
      "         5.9530e-01, -6.0693e-01,  5.6218e-01, -5.6210e-01, -5.9293e-02,\n",
      "         1.9160e-01, -8.3824e-01, -4.5230e-01, -3.6127e-01,  2.6998e-01,\n",
      "        -5.5006e-01, -2.0634e-01, -1.4360e-01,  1.9234e-02,  2.2073e-02,\n",
      "        -3.1253e-01,  1.8183e-01, -1.9572e-01, -1.5695e-01,  1.5988e-02,\n",
      "         4.2149e-01, -7.0676e-01, -7.6097e-01,  5.0228e-01,  5.7912e-02,\n",
      "         1.3576e-01,  7.3253e-02, -5.5494e-01,  3.7011e-01, -1.6185e-01,\n",
      "        -4.6946e-01, -6.2545e-01, -4.9450e-02,  9.8939e-01,  1.0873e-01,\n",
      "        -2.5797e-01,  2.4423e-01, -4.8729e-02, -1.0961e-02, -9.5689e-02,\n",
      "        -2.5774e-01,  6.4918e-02, -7.7223e-02, -2.2893e-01, -1.9216e-01,\n",
      "         1.8599e-01,  3.6994e-01,  4.6237e-02,  4.9634e-01, -1.3000e-01,\n",
      "        -3.2309e-01,  3.4855e-01, -4.2707e-01,  2.6523e-02, -3.0895e-01,\n",
      "        -4.1076e-01, -3.6196e-01,  2.8411e-01, -6.5514e-02,  2.9661e-01,\n",
      "        -5.3147e-01,  3.1170e-01,  6.5914e-01,  4.0405e-01, -5.1264e-01,\n",
      "         6.2857e-02, -1.7284e-01,  8.4184e-01,  2.1049e-01, -5.2210e-01,\n",
      "         3.1595e-01, -3.6681e-02,  3.5338e-01, -1.7072e-01,  3.4897e-02,\n",
      "        -2.1846e-01,  5.6417e-01,  2.8268e-01, -6.9117e-02,  5.0127e-01,\n",
      "        -6.1327e-01, -2.8064e-01, -1.5187e-01, -1.1815e-01, -1.8324e-01,\n",
      "        -5.0160e-02,  4.4803e-02,  9.8757e-02,  2.8890e-01,  1.3924e-01,\n",
      "        -9.4842e-02, -2.2525e-01,  5.0518e-01,  2.5869e-01,  6.1433e-01,\n",
      "         1.8569e-01, -3.2148e-01, -4.8556e-01, -2.2274e-01, -4.3261e-01,\n",
      "         2.6900e-01,  1.4272e-01, -5.9336e-02,  7.0397e-02,  1.7427e-01,\n",
      "         7.1034e-01, -2.0042e-01,  5.8759e-01,  6.8344e-02, -2.2413e-01,\n",
      "         3.2460e-01,  4.3674e-01, -2.2553e-01, -2.3609e-01, -4.0683e-01,\n",
      "         3.3984e-01,  1.5630e-01,  2.8995e-01, -1.2948e-01, -7.0831e-01,\n",
      "         5.9399e-01,  1.4602e-01,  3.3806e-01, -1.9211e-01,  1.4535e-01,\n",
      "         3.9888e-01,  2.1713e-01,  2.5934e-01, -4.2541e-02, -8.7617e-01,\n",
      "        -2.9714e-01, -3.0809e-01, -6.3623e-01,  4.8156e-01, -3.2286e-01,\n",
      "        -3.7964e-02,  2.1735e-01,  4.2631e-01,  5.2317e-01, -6.5835e-01,\n",
      "         1.5155e-02,  1.8193e-01,  1.7193e-01,  4.4541e-02, -5.8563e-01,\n",
      "         6.9942e-02,  1.7092e-01, -5.6155e-01,  3.0635e-01, -9.8620e-03,\n",
      "         1.0578e-01, -9.3809e-02,  5.7440e-01, -1.5635e-01,  1.6229e-01,\n",
      "         4.5916e-01,  9.4176e-02, -6.7046e-01,  3.1491e-01,  4.4583e-01,\n",
      "        -8.0306e-01,  1.1808e-01,  1.0641e-01, -1.9740e-01,  6.7404e-02,\n",
      "         3.2159e-01,  2.7101e-01, -1.2578e-01,  5.1103e-01, -1.7545e-01,\n",
      "         8.9525e-01, -6.4643e-01, -4.2853e-01, -1.3646e-01,  7.7879e-02,\n",
      "         1.3411e-01,  4.1613e-01, -7.8858e-01,  3.6745e-02, -8.4204e-03,\n",
      "         8.0198e-02,  1.4876e-02,  1.0820e-01,  3.3174e-01,  4.0886e-01,\n",
      "         8.7196e-01, -7.8535e-02,  2.4204e-01,  2.9743e-01, -8.6555e-01,\n",
      "         2.9365e-01, -9.9672e-03,  3.4741e-02, -1.4608e-01, -8.1257e-01,\n",
      "         4.3998e-01,  4.0535e-01,  4.3317e-01, -2.4574e-01, -2.9825e-01,\n",
      "         6.2417e-01, -2.6741e-01, -4.2314e-02,  3.3152e-02, -2.4543e-01,\n",
      "         6.3680e-01,  6.2761e-01, -2.5183e-01,  4.5455e-01,  4.2125e-01,\n",
      "         2.0972e-01,  4.5685e-01, -4.5635e-01,  1.6889e-01,  1.1491e-01,\n",
      "        -2.2291e-02,  2.1095e-02, -7.4251e-02, -9.0196e-02,  6.2297e-01,\n",
      "         3.3649e-01, -3.1688e-02,  3.8870e-01, -3.3094e-01,  1.8062e-01,\n",
      "        -4.2337e-01,  3.3824e-01, -3.5491e-01,  5.0927e-01,  5.6322e-01,\n",
      "         2.8225e-02,  7.2463e-02,  4.4793e-01, -5.8691e-01, -2.7691e-02,\n",
      "         8.0589e-01,  1.5816e-01,  1.3195e-01,  3.0109e-02,  7.2165e-02,\n",
      "        -1.1245e-01,  5.8278e-01,  3.9749e-02,  3.6279e-01,  6.2839e-01,\n",
      "         1.0262e-01, -1.9061e-01,  1.1738e-02,  1.7280e-01,  4.2340e-01,\n",
      "        -5.5208e-02, -9.1506e-01,  1.0025e+00, -3.8197e-01, -2.3269e-01,\n",
      "         5.8361e-02,  6.2680e-01,  3.2440e-01, -2.1381e-01,  7.4027e-01,\n",
      "         1.2751e-01, -2.4027e-01, -1.0814e-01, -2.6318e-01,  8.7558e-02,\n",
      "        -2.6277e-01, -2.6949e-01, -1.1915e-01,  7.4802e-01, -2.5161e-01,\n",
      "         1.3492e-01,  3.0204e-01,  4.0225e-01,  4.3357e-02, -2.5283e-02,\n",
      "        -2.0326e-01, -2.5037e-01,  2.0941e-01,  1.8616e-02,  1.6610e-01,\n",
      "         3.4838e-01, -1.1664e-01,  1.5880e-01, -1.3966e-01,  1.2907e-01,\n",
      "         2.1776e-01, -2.5573e-01, -2.8968e-01, -9.2601e-02, -3.1237e-02,\n",
      "        -3.0190e-01, -1.2639e-01,  9.6939e-02,  8.0843e-02,  1.1105e-01,\n",
      "        -7.5512e-03, -3.7326e-01], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(labels.loc[0, 2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.2743e+01, 4.5951e+01, 5.6947e+01, 7.6523e+11, 7.5514e+11, 7.4267e+11,\n",
       "         7.5617e+11, 7.6696e+11, 7.6777e+11, 7.3560e+11, 7.6166e+11, 7.3166e+11,\n",
       "         7.4869e+11, 7.6578e+11, 7.6710e+11, 7.5890e+11]], device='cuda:0',\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def kldiv_loss(free_bit, p: Normal, q: Normal, attention_mask: torch.Tensor = None, use_free_bit: bool = True):\n",
    "    zkl_real = kl_divergence(p, q).mean(-1)\n",
    "\n",
    "    if attention_mask is not None:\n",
    "        attn_sum = attention_mask.sum()\n",
    "        zkl_real = zkl_real.masked_fill(attention_mask == 0, 0.0)\n",
    "    else:\n",
    "        attn_sum = p.loc.shape[0] * p.loc.shape[1]\n",
    "\n",
    "    if use_free_bit:\n",
    "        kl_mask = torch.gt(zkl_real, free_bit)\n",
    "        zkl = zkl_real[kl_mask].sum() / attn_sum\n",
    "        zkl_real = zkl_real.sum() / attn_sum\n",
    "\n",
    "        return zkl, zkl_real\n",
    "    else:\n",
    "        zkl_real = zkl_real.sum() / attn_sum\n",
    "        return zkl_real\n",
    "        \n",
    "# kldiv_loss(\n",
    "#     0.5,\n",
    "#     x,\n",
    "#     labels,\n",
    "#     attention_mask = item[\"attention_mask\"],\n",
    "#     use_free_bit=False\n",
    "# )\n",
    "kl_divergence(x, labels).mean(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
