{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from coop import VAE, util\n",
    "\n",
    "from transformers import BertForMaskedLM, RobertaForMaskedLM, AutoTokenizer, AutoConfig, RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaEncoder\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from diffusers import DDPMScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class DiffusionLMDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, encoder):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __getitem__(self, index):\n",
    "        text = self.dataset[index]['sentence']\n",
    "        # text = self.samples[index % len(self.samples)]\n",
    "        latent = self.encoder.encode(text)[0]\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            \"latent\": latent\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Denoiser(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, num_timesteps) -> None:\n",
    "        super().__init__()\n",
    "        self.temb = nn.Embedding(num_timesteps, d_model)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.Linear(d_model, d_model, bias=False),\n",
    "            nn.BatchNorm1d(d_model)\n",
    "        ) \n",
    "        self.apply(self._init_weights)\n",
    "        self.layers.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=.1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=.1)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "\n",
    "    def forward(self, sample, timesteps):\n",
    "        if timesteps.dim() == 0:\n",
    "            timesteps = timesteps.repeat(sample.shape[0])\n",
    "\n",
    "        timesteps = timesteps.unsqueeze(1)\n",
    "        temb = self.temb(timesteps).squeeze(1)\n",
    "        # print(timesteps.shape, temb.shape)\n",
    "        inputs = sample + temb\n",
    "\n",
    "        return self.layers(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3046, -0.7496,  0.6473,  ..., -1.8801, -2.9748,  0.6735],\n",
       "        [-1.3606, -1.0630, -0.4759,  ...,  0.4855,  2.2265, -0.0574],\n",
       "        [-0.7467, -0.1631, -1.7546,  ..., -0.2479,  0.7193, -0.7275],\n",
       "        ...,\n",
       "        [-0.6167,  1.5043,  0.0919,  ...,  0.8858, -1.8099,  0.7938],\n",
       "        [-2.4096,  1.6831, -0.3536,  ..., -0.4391,  1.8757,  0.8847],\n",
       "        [ 0.9527,  0.4379, -0.5125,  ..., -0.7583,  0.3861, -0.7880]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(256, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HEEGYU~1\\AppData\\Local\\Temp/ipykernel_17428/2374878992.py:3: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  pred = model(noise, torch.range(0, 511, 2).long())\n"
     ]
    }
   ],
   "source": [
    "model = Denoiser(512, 1000)\n",
    "noise = torch.randn(256, 512)\n",
    "pred = model(noise, torch.range(0, 511, 2).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9923, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(pred, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.3069e-01,  3.7570e-01,  6.2253e-01, -6.5380e-02,  6.9206e-01,\n",
       "        -3.0845e-01,  3.0219e-01,  3.0976e-01,  1.0527e+00, -2.6762e-01,\n",
       "        -4.0918e-01,  5.6203e-01, -3.5050e-01,  1.2583e-02,  3.9682e-01,\n",
       "        -1.7870e-01,  1.1084e-01, -2.2941e-02,  5.0350e-01,  3.5709e-01,\n",
       "        -3.1168e-01,  2.9955e-01,  3.5144e-01, -9.9309e-01,  4.4857e-01,\n",
       "        -1.7210e-01,  7.7213e-01, -5.2795e-01, -1.4216e-01,  4.5034e-01,\n",
       "        -5.8754e-01, -2.6688e-01,  2.3094e-01, -6.4043e-03, -1.0348e+00,\n",
       "        -2.7378e-02,  4.3144e-01, -7.3601e-01, -1.9160e-01,  4.4092e-01,\n",
       "         2.5409e-01,  4.6629e-01, -2.8723e-01,  1.7398e-01, -3.8133e-01,\n",
       "        -3.0278e-02,  8.8214e-02,  1.1033e-01,  4.0606e-01,  2.1244e-02,\n",
       "        -5.6933e-01, -1.8464e-01, -1.7351e-01,  6.4978e-01, -2.3459e-01,\n",
       "         7.2628e-01, -2.2024e-01,  5.0332e-02, -2.4567e-01, -1.4583e-02,\n",
       "        -4.8528e-01,  9.2317e-02, -4.5601e-01,  2.4446e-01,  2.6013e-02,\n",
       "        -1.3395e-01,  3.3500e-01,  5.4757e-01,  1.4514e-01, -5.0320e-01,\n",
       "         5.7297e-01, -4.5698e-01, -5.5001e-01, -6.7077e-02,  5.5194e-03,\n",
       "         4.0581e-01,  3.3643e-01,  1.9273e-01,  4.4540e-01, -8.4673e-01,\n",
       "         9.5913e-02,  4.9207e-01,  2.2136e-01, -3.7995e-01, -3.9910e-01,\n",
       "         3.7703e-01,  4.9281e-01, -6.1342e-01, -2.9274e-01,  1.6588e-01,\n",
       "        -1.9355e-01, -3.8749e-01,  3.6329e-01, -5.0671e-02,  2.8462e-01,\n",
       "         7.5090e-01, -7.5270e-01,  6.0230e-01, -1.6697e-01,  4.1594e-01,\n",
       "        -4.3120e-01,  2.5158e-01, -1.0218e+00,  3.6483e-01,  3.7107e-01,\n",
       "        -2.3930e-01, -4.6005e-01,  9.0330e-02, -1.0052e-01, -4.1185e-01,\n",
       "         5.0622e-02,  3.0618e-01, -9.8913e-02, -1.3333e-01,  1.8031e-01,\n",
       "         1.9787e-01, -1.2955e-01, -1.7726e-01, -3.3446e-02,  1.6755e-01,\n",
       "         1.1622e-01,  2.4960e-01,  4.8702e-02, -2.7329e-03, -1.0126e-01,\n",
       "         3.9107e-01, -1.0172e-01, -3.2333e-01, -9.8561e-02, -4.1220e-01,\n",
       "         2.1421e-01, -2.3813e-01, -1.0953e-01,  1.7593e-01, -3.0705e-01,\n",
       "         2.9282e-02, -1.2932e-01,  1.8989e-01,  6.6472e-01,  1.5370e-01,\n",
       "         2.0061e-02,  1.3608e-01, -2.7225e-01,  2.1898e-01,  1.5622e-01,\n",
       "         3.0853e-01,  3.3676e-01,  3.6668e-01, -3.7244e-01,  6.9107e-02,\n",
       "        -3.8805e-01, -1.1576e-01,  5.9142e-01, -2.3876e-02,  1.5551e-01,\n",
       "         1.6338e-01,  2.1020e-01, -6.4025e-01,  3.9267e-01,  2.8704e-01,\n",
       "         5.0552e-01, -8.0168e-02, -1.6850e-01, -5.2790e-01,  7.0148e-01,\n",
       "         1.6839e-01,  1.4524e-01, -6.2863e-01,  2.3506e-01,  3.8862e-02,\n",
       "         5.3978e-01,  6.6722e-01, -8.2212e-01,  2.5078e-01,  3.0711e-01,\n",
       "        -2.5944e-01,  3.1088e-01, -1.5106e-01, -6.9502e-01, -5.9894e-01,\n",
       "         1.2102e-01, -1.8953e-01, -8.9990e-02,  4.2799e-02,  1.3810e-01,\n",
       "         2.5246e-02, -2.8004e-01, -4.4929e-01, -3.7796e-01, -4.2634e-01,\n",
       "         4.2054e-01,  1.9835e-01,  2.7483e-01, -4.6391e-01,  7.0142e-01,\n",
       "         6.4028e-01,  2.3803e-02, -3.8498e-01,  6.2926e-01,  1.1042e-01,\n",
       "        -6.2346e-01, -2.1766e-01,  1.3781e-01,  3.6508e-01, -8.0298e-01,\n",
       "        -7.9136e-02,  5.2610e-01,  1.7093e-01,  3.7370e-01,  4.1996e-01,\n",
       "         4.5541e-01, -3.8269e-01, -1.0005e+00, -4.2196e-01,  4.3818e-01,\n",
       "        -2.8839e-01,  3.7900e-01,  1.5184e-01, -7.2307e-01, -3.3126e-01,\n",
       "        -3.8273e-02, -1.9627e-01, -3.3454e-01,  9.0992e-04,  5.3341e-01,\n",
       "         4.5239e-01,  8.9701e-02, -1.3238e-02, -9.0327e-01,  2.4317e-01,\n",
       "        -2.6453e-02,  1.9534e-01, -5.4405e-01, -2.6452e-02,  4.5805e-01,\n",
       "         8.9830e-02,  8.3710e-01, -2.1804e-01, -9.6553e-02, -8.6805e-02,\n",
       "         4.6018e-01,  3.4116e-02,  3.4968e-01,  6.3002e-02, -6.2748e-02,\n",
       "        -4.0921e-01,  1.6024e-01, -4.0750e-01,  1.1478e+00,  6.6401e-01,\n",
       "         1.8902e-01, -2.1835e-01, -6.6902e-02, -3.3136e-01,  1.2512e-02,\n",
       "        -2.2288e-01, -2.3175e-01,  8.0487e-02,  6.2907e-02, -2.4802e-01,\n",
       "         1.0426e+00,  2.6975e-01, -3.6895e-01,  2.3008e-01,  8.3248e-02,\n",
       "         3.2291e-01,  4.8535e-01,  7.5826e-01,  7.7213e-03, -4.1028e-01,\n",
       "        -3.3565e-01,  2.7632e-02, -2.6448e-01, -2.4792e-01, -4.6477e-01,\n",
       "        -2.9963e-01,  6.7049e-02, -3.5989e-01, -4.2949e-01,  4.9667e-02,\n",
       "        -3.4357e-01,  7.6515e-01, -2.9758e-01,  2.8262e-01,  1.3527e-01,\n",
       "        -2.9886e-01,  3.9307e-01,  1.0509e-01,  5.4350e-01,  2.3915e-01,\n",
       "         6.6884e-02, -1.2804e-01, -8.9876e-01,  1.6123e-01, -5.9324e-02,\n",
       "         7.1965e-02, -4.1312e-01, -1.8923e-01,  6.8917e-01, -7.2448e-02,\n",
       "         2.1999e-01, -1.7936e-01,  1.0476e-01,  9.9724e-01, -4.6101e-01,\n",
       "         2.1785e-01, -1.4371e-01, -9.1177e-01, -3.6727e-01,  2.8463e-01,\n",
       "        -6.3901e-01,  1.5094e-02, -7.2256e-02,  1.6871e-01,  1.2236e-01,\n",
       "         2.0925e-02,  2.6155e-01,  3.0195e-01, -8.1667e-02,  2.1795e-01,\n",
       "         5.5354e-01, -7.7065e-02,  3.3090e-01, -2.7591e-01, -1.2556e-01,\n",
       "        -3.5366e-01,  7.4347e-02, -1.8188e-01,  2.6085e-01,  3.5685e-01,\n",
       "         2.7003e-01, -3.7489e-01,  3.3904e-01,  1.0340e-01,  3.1419e-01,\n",
       "         2.9340e-02, -8.7289e-01, -4.9123e-01, -6.1812e-01, -7.1640e-02,\n",
       "         8.6137e-02, -4.7875e-01, -2.1450e-01,  3.0026e-01, -6.2216e-02,\n",
       "         1.1921e-01, -2.9851e-01, -1.4033e-01, -5.0546e-01, -2.5340e-01,\n",
       "        -4.3134e-01, -4.2264e-02, -6.3221e-01,  2.1980e-01, -7.0547e-01,\n",
       "         6.8467e-01,  6.0466e-01, -4.0093e-01, -5.5385e-01, -1.4389e-01,\n",
       "        -1.6544e-01, -3.6977e-02, -3.9759e-01, -2.9548e-01, -6.6688e-01,\n",
       "         7.9555e-02,  6.6589e-01, -3.0826e-01,  6.6670e-01,  3.0481e-02,\n",
       "         2.2358e-01,  2.3780e-01, -1.7305e-01,  9.4196e-01, -5.7423e-01,\n",
       "         9.7549e-01, -7.7374e-02,  4.3035e-01,  1.8030e-02, -1.1043e-01,\n",
       "        -2.7612e-01, -5.6633e-01,  5.3185e-02, -1.6216e-01, -5.6135e-01,\n",
       "        -2.6179e-01, -6.0868e-01, -2.1226e-01,  5.9753e-02,  2.6010e-01,\n",
       "        -3.4878e-01,  4.1038e-01,  5.8868e-01, -2.2517e-01,  5.9960e-01,\n",
       "        -5.8442e-01, -3.4298e-01,  3.7067e-01,  3.1435e-01, -2.2308e-01,\n",
       "         4.3860e-01,  3.4107e-01, -1.9424e-02,  4.2924e-01, -1.0345e-01,\n",
       "         3.4726e-02, -1.2000e-01,  2.6048e-01, -9.6064e-02, -4.3766e-01,\n",
       "        -5.0887e-01, -6.6154e-01, -1.6828e-01, -1.3139e-01,  4.7710e-01,\n",
       "        -2.3627e-01,  2.0843e-01,  5.2400e-03,  2.2166e-02,  2.3006e-01,\n",
       "        -1.0142e+00, -5.9770e-01, -5.0319e-01,  6.7160e-01,  4.6689e-01,\n",
       "         5.6641e-01, -7.7958e-01,  6.2763e-01, -2.8546e-01,  8.2711e-02,\n",
       "        -1.0048e+00,  4.7223e-01,  5.2221e-01, -7.2463e-02, -8.0950e-02,\n",
       "         1.5727e-01,  2.7177e-01,  1.6701e-01, -2.9027e-01, -3.5177e-01,\n",
       "        -4.9532e-02,  7.0304e-01, -7.7899e-01,  1.7719e-01, -5.8199e-01,\n",
       "        -8.8956e-01,  2.6041e-01,  2.8442e-01, -3.6009e-01, -3.3176e-01,\n",
       "         1.7984e-02, -4.4138e-01, -5.9013e-01,  1.0017e-01,  1.0334e-01,\n",
       "        -3.2371e-01,  6.2189e-01, -5.9477e-03, -1.7597e-01, -5.4203e-01,\n",
       "        -2.6161e-01, -2.3686e-01,  6.8388e-01, -6.5361e-01,  9.4150e-01,\n",
       "         5.5765e-01, -2.4277e+00,  1.0168e-01,  5.2529e-01,  2.6629e-02,\n",
       "        -6.0368e-01, -2.1125e-02,  4.5018e-01, -3.3687e-01, -2.0234e-01,\n",
       "        -3.4874e-01,  4.6636e-01, -9.4671e-01, -1.9194e-01,  6.3362e-01,\n",
       "         4.7321e-01,  4.8701e-01,  4.4652e-01, -1.1380e-01,  5.5531e-01,\n",
       "        -3.4097e-01,  6.5032e-01, -7.5993e-02,  2.8720e-01,  3.7724e-01,\n",
       "        -3.4261e-01,  1.1187e-01,  1.8481e-01, -4.8412e-02, -3.0901e-01,\n",
       "         1.1249e+00,  1.9769e-01, -6.7480e-01, -1.5113e-01,  8.2268e-01,\n",
       "         2.1835e-01,  1.4591e-01,  4.8543e-01,  2.5288e-01,  2.7179e-01,\n",
       "         3.5185e-01,  2.6757e-01,  2.5484e-01, -6.1407e-01, -1.6865e-02,\n",
       "        -3.9458e-01,  9.8406e-01], device='cuda:0')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"latent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers.pipeline_utils import DiffusionPipeline\n",
    "\n",
    "\n",
    "def get_noise_sample(shape, device):\n",
    "    noise = torch.randn(shape).to(device)\n",
    "    return noise\n",
    "    \n",
    "class DDPMPipeline(DiffusionPipeline):\n",
    "    def __init__(self, model, scheduler, sample_shape, device='cuda'):\n",
    "        super().__init__()\n",
    "        self.scheduler = scheduler.set_format(\"pt\")\n",
    "        self.model = model\n",
    "        self.sample_shape = sample_shape\n",
    "        self.device = device\n",
    "        # self.register_modules(model=model, scheduler=scheduler)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, batch_size=1, generator=None, output_type=\"pil\", **kwargs):\n",
    "        # Sample gaussian noise to begin loop\n",
    "        image = torch.randn(\n",
    "            (batch_size, ) + self.sample_shape,\n",
    "            generator=generator,\n",
    "        )\n",
    "        image = image.to(self.device)\n",
    "\n",
    "        # set step values\n",
    "        self.scheduler.set_timesteps(self.scheduler.num_train_timesteps)\n",
    "\n",
    "        for t in tqdm(self.scheduler.timesteps, desc=\"ddpm sampling\"):\n",
    "            # 1. predict noise model_output\n",
    "            model_output = self.model(image, t.to(self.device))\n",
    "\n",
    "            # 2. compute previous image: x_t -> t_t-1\n",
    "            image = self.scheduler.step(model_output, t, image)[\"prev_sample\"]\n",
    "\n",
    "        return {\"sample\": image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "    config,\n",
    "    denoiser,\n",
    "    vae,\n",
    "    noise_scheduler,\n",
    "    optimizer,\n",
    "    dataloader,\n",
    "    device='cuda'\n",
    "):\n",
    "    denoiser = denoiser.train().to(device)\n",
    "    vae = vae.eval().to(device)\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        losses = []\n",
    "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            clean_samples = batch['latent'].to(device)\n",
    "            noise = get_noise_sample(clean_samples.shape, device)\n",
    "            \n",
    "            batch_size = clean_samples.shape[0]\n",
    "            timesteps = torch.randint(\n",
    "                1, \n",
    "                noise_scheduler.num_train_timesteps, \n",
    "                (batch_size,)\n",
    "                ).long().to(device)\n",
    "            \n",
    "            noisy_samples = noise_scheduler.add_noise(clean_samples, noise, timesteps)\n",
    "            # noisy_samples_prev = noise_scheduler.add_noise(clean_samples, noise, timesteps - 1)\n",
    "\n",
    "            noise_pred = denoiser(noisy_samples, timesteps)\n",
    "            # print(noisy_samples.shape, noise_pred.shape, noise.shape)\n",
    "            # loss = F.mse_loss(noise_pred, noise)\n",
    "            loss = F.kl_div(noise_pred, noise, reduction=\"batchmean\")\n",
    "            loss.backward()\n",
    "            # print(loss.item())\n",
    "            torch.nn.utils.clip_grad_norm_(denoiser.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "        print(\"mean loss:\", np.mean(losses))\n",
    "\n",
    "        if (epoch + 1) % config.eval_epochs == 0:\n",
    "            # with torch.no_grad():\n",
    "            #     sample_size = 10\n",
    "            #     eval_noise_shape = (sample_size, config['seq_len'], config['d_model'])\n",
    "            #     samples = get_noise_sample(eval_noise_shape, device)\n",
    "\n",
    "            #     for step in tqdm(reversed(range(noise_scheduler.num_train_timesteps))):\n",
    "            #         samples = model(samples, torch.LongTensor([step] * sample_size).to(device)).last_hidden_state\n",
    "            #         # samples = noise_scheduler.step(denoised, step, samples)[\"prev_sample\"]\n",
    "                \n",
    "            #     sample_logits = encoder_model.lm_head(samples).cpu().argmax(-1)\n",
    "            #     print(tokenizer.batch_decode(sample_logits, skip_special_tokens=False))\n",
    "            \n",
    "            pipeline = DDPMPipeline(denoiser, noise_scheduler, (config.d_model, ))\n",
    "            samples = pipeline(\n",
    "                batch_size = config.eval_batch_size, \n",
    "                generator=torch.manual_seed(32)\n",
    "            )[\"sample\"]\n",
    "            samples = vae.generate(samples)\n",
    "            print(samples)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    epochs = 50\n",
    "    batch_size = 32\n",
    "    learning_rate = 1e-4\n",
    "    seq_len = 512\n",
    "    d_model = 512\n",
    "    diffusion_timesteps = 1000\n",
    "    eval_epochs = 5\n",
    "    eval_batch_size = 8\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:560: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name: str = \"megagonlabs/bimeanvae-yelp\"  # or \"megagonlabs/bimeanvae-amzn\", \"megagonlabs/optimus-yelp\", \"megagonlabs/optimus-amzn\"\n",
    "vae = VAE(model_name)\n",
    "denoiser = Denoiser(config.d_model, config.diffusion_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\heegyukim\\.cache\\huggingface\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "dataset = DiffusionLMDataset(\n",
    "    load_dataset(\"glue\", name=\"cola\", split=\"train\"),\n",
    "    # load_dataset(\"nsmc\", split=\"train\"),\n",
    "    encoder=vae\n",
    ")\n",
    "ddpm = DDPMScheduler(num_train_timesteps=config.diffusion_timesteps, tensor_format=\"pt\")\n",
    "train_loader = DataLoader(dataset, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(denoiser.parameters(), lr=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 268/268 [00:19<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss: -19968.41914736335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 268/268 [00:19<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss: -19846.274093400185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 268/268 [00:19<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss: -19816.769370918842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 268/268 [00:19<00:00, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss: -19797.126013001398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 268/268 [00:19<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss: -19782.793639225747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ddpm sampling: 100%|██████████| 1000/1000 [00:00<00:00, 1535.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I've been here 3 times now and wish I had gotten the best Kalbi sandwich I've ever had. Great sandwhiches, sandwiches, and shakes. Service is okay.\", \"I've been here 3 times now and wish I had gotten the best Kalbi sandwich I've ever had. Great sandwhiches, sandwiches, and shakes. Service is okay.\", \"I've been here 3 times now and wish I had gotten the best Kalbi sandwich I've ever had. Great sandwhiches, sandwiches, and shakes. Service is okay.\", \"I've been here 3 times now and wish I had gotten the best Kalbi sandwich I've ever had. Great sandwhiches, sandwiches, and shakes. Service is okay.\", \"I've been here 3 times now and wish I had gotten the best Kalbi sandwich I've ever had. Great sandwhiches, sandwiches, and shakes. Service is okay.\", \"I've been here 3 times now and wish I had gotten the best Kalbi sandwich I've ever had. Great sandwhiches, sandwiches, and shakes. Service is okay.\", \"I've been here 3 times now and wish I had gotten the best Kalbi sandwich I've ever had. Great sandwhiches, sandwiches, and shakes. Service is okay.\", \"I've been here 3 times now and wish I had gotten the best Kalbi sandwich I've ever had. Great sandwhiches, sandwiches, and shakes. Service is okay.\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:  45%|████▍     | 120/268 [00:08<00:10, 13.91it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HEEGYU~1\\AppData\\Local\\Temp/ipykernel_17428/3841052663.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_loop(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdenoiser\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvae\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mddpm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\HEEGYU~1\\AppData\\Local\\Temp/ipykernel_17428/3208575807.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(config, denoiser, vae, noise_scheduler, optimizer, dataloader, device)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf\"Epoch {epoch + 1}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mclean_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'latent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mper_device_and_dtype_grads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_zero_grad_profile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_function_enter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loop(\n",
    "    config,\n",
    "    denoiser,\n",
    "    vae,\n",
    "    ddpm,\n",
    "    optimizer,\n",
    "    train_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
       " [\"Our friends won't let this place alone, the food is great.\"])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = dataset[0][\"text\"]\n",
    "text, vae.generate(vae.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name: str = \"megagonlabs/bimeanvae-yelp\"  # or \"megagonlabs/bimeanvae-amzn\", \"megagonlabs/optimus-yelp\", \"megagonlabs/optimus-amzn\"\n",
    "vae = VAE(model_name)\n",
    "\n",
    "reviews: List[str] = [\n",
    "    \"I love this ramen shop!! Highly recommended!!\",\n",
    "    \"Here is one of my favorite ramen places! You must try!\"\n",
    "]\n",
    "z_raw: torch.Tensor = vae.encode(reviews[0]) # [num_reviews * latent_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love this ramen shop!! Highly recommended!',\n",
       " 'Here is one of my favorite ramen places! You must try this place!']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.generate(z_raw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
